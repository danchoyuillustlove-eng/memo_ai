"""
AI ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (AI Prompt Construction)

Notionã¸ã®ãƒ‡ãƒ¼ã‚¿ç™»éŒ²ã‚„ãƒãƒ£ãƒƒãƒˆå¿œç­”ã®ãŸã‚ã«ã€AIï¼ˆLLMï¼‰ã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ‹…å½“ã—ã¾ã™ã€‚
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚­ãƒ¼ãƒæ§‹é€ ã‚„éå»ã®ãƒ‡ãƒ¼ã‚¿ä¾‹ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€
AIãŒé©åˆ‡ãªJSONå½¢å¼ã§å›ç­”ã§ãã‚‹ã‚ˆã†ã«èª˜å°ã—ã¾ã™ã€‚
"""
import json
from typing import Dict, Any, List, Optional

from api.llm_client import generate_json, prepare_multimodal_prompt
from api.models import select_model_for_input


def construct_prompt(
    text: str,
    schema: Dict[str, Any],
    recent_examples: List[Dict[str, Any]],
    system_prompt: str
) -> str:
    """
    ã‚¿ã‚¹ã‚¯æŠ½å‡ºãƒ»ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æ¨å®šã®ãŸã‚ã®å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
    
    Args:
        text (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        schema (Dict): å¯¾è±¡Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±
        recent_examples (List): ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç›´è¿‘ã®ç™»éŒ²ãƒ‡ãƒ¼ã‚¿ï¼ˆFew-shotå­¦ç¿’ç”¨ï¼‰
        system_prompt (str): AIã¸ã®å½¹å‰²æŒ‡ç¤ºï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
        
    Returns:
        str: LLMã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—å…¨ä½“
    """
    # 1. ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã®æ•´å½¢
    # AIãŒç†è§£ã—ã‚„ã™ã„ã‚ˆã†ã«ã€Notionã®è¤‡é›‘ãªã‚¹ã‚­ãƒ¼ãƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç°¡ç•¥åŒ–ã—ã¾ã™ã€‚
    # ä¾‹: {"Status": "select options: ['æœªç€æ‰‹', 'é€²è¡Œä¸­', 'å®Œäº†']"}
    schema_info = {}
    for k, v in schema.items():
        schema_info[k] = v['type']
        # é¸æŠè‚¢ãŒã‚ã‚‹ã‚¿ã‚¤ãƒ—ï¼ˆselect, multi_selectï¼‰ã®å ´åˆã¯ã€é¸æŠè‚¢ã‚‚åˆ—æŒ™ã—ã¦AIã«ä¼ãˆã¾ã™ã€‚
        if v['type'] == 'select':
            schema_info[k] += f" options: {[o['name'] for o in v['select']['options']]}"
        elif v['type'] == 'multi_select':
            schema_info[k] += f" options: {[o['name'] for o in v['multi_select']['options']]}"
            
    # 2. éå»ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢ (Few-shot prompting)
    # éå»ã®ãƒ‡ãƒ¼ã‚¿ä¾‹ã‚’æç¤ºã™ã‚‹ã“ã¨ã§ã€AIã«å…¥åŠ›ã®å‚¾å‘ã‚„æœŸå¾…ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å­¦ç¿’ã•ã›ã¾ã™ã€‚
    examples_text = ""
    if recent_examples:
        for ex in recent_examples:
            props = ex.get("properties", {})
            simple_props = {}
            # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å‹ã«å¿œã˜ã¦å€¤ã‚’æŠ½å‡ºãƒ»ç°¡ç•¥åŒ–
            for k, v in props.items():
                p_type = v.get("type")
                val = "N/A"
                if p_type == "title":
                    val = "".join([t.get("plain_text", "") for t in v.get("title", [])])
                elif p_type == "rich_text":
                    val = "".join([t.get("plain_text", "") for t in v.get("rich_text", [])])
                elif p_type == "select":
                    val = v.get("select", {}).get("name") if v.get("select") else None
                elif p_type == "multi_select":
                    val = [o.get("name") for o in v.get("multi_select", [])]
                elif p_type == "date":
                    val = v.get("date", {}).get("start") if v.get("date") else None
                elif p_type == "checkbox":
                    val = v.get("checkbox")
                simple_props[k] = val
            examples_text += f"- {json.dumps(simple_props, ensure_ascii=False)}\n"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ„ã¿ç«‹ã¦
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + ã‚¹ã‚­ãƒ¼ãƒå®šç¾© + ãƒ‡ãƒ¼ã‚¿ä¾‹ + ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ› ã‚’çµåˆ
    prompt = f"""
{system_prompt}

Target Database Schema:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

Recent Examples:
{examples_text}

User Input:
{text}

Output JSON format strictly. NO markdown code blocks.
"""
    return prompt


def construct_chat_prompt(
    text: str,
    schema: Dict[str, Any],
    system_prompt: str,
    session_history: Optional[List[Dict[str, str]]] = None
) -> str:
    """
    ãƒãƒ£ãƒƒãƒˆå¯¾è©±ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    
    ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
    ä¼šè©±å±¥æ­´ï¼ˆsession_historyï¼‰ã‚’å«ã‚ã‚‹ã“ã¨ã§ã€æ–‡è„ˆã‚’è¸ã¾ãˆãŸå¿œç­”ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
    """
    schema_info = {}
    target_type = "database"
    
    # ã‚¹ã‚­ãƒ¼ãƒåˆ¤å®š: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã‹ãƒšãƒ¼ã‚¸ã‚¹ã‚­ãƒ¼ãƒã‹
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´åˆã¯å„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å®šç¾©ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
    # ãƒšãƒ¼ã‚¸ã®å ´åˆã¯å›ºå®šã‚¹ã‚­ãƒ¼ãƒï¼ˆTitle, Contentãªã©ï¼‰ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚
    
    for k, v in schema.items():
        if isinstance(v, dict) and "type" in v:
             schema_info[k] = v['type']
             if v['type'] == 'select' and 'select' in v:
                schema_info[k] += f" options: {[o['name'] for o in v['select']['options']]}"
             elif v['type'] == 'multi_select' and 'multi_select' in v:
                schema_info[k] += f" options: {[o['name'] for o in v['multi_select']['options']]}"
    
    # ä¼šè©±å±¥æ­´ã®ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    # å½¹å‰²ï¼ˆRoleï¼‰ã¨å†…å®¹ï¼ˆContentï¼‰ã‚’æ˜è¨˜ã—ã¦ã€éå»ã®ã‚„ã‚Šå–ã‚Šã‚’æ™‚ç³»åˆ—ã§è¨˜è¿°ã—ã¾ã™ã€‚
    # Systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€AIã¸ã®è¿½åŠ æŒ‡ç¤ºã¨ã—ã¦æ‰±ã„ã¾ã™ï¼ˆä¾‹ï¼šå‚ç…§ãƒšãƒ¼ã‚¸ã®æœ¬æ–‡ãªã©ï¼‰ã€‚
    history_text = ""
    if session_history:
        for msg in session_history:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role == "system":
                 history_text += f"[System Info]: {content}\n"
            else:
                 history_text += f"{role.upper()}: {content}\n"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸ã®åŸ‹ã‚è¾¼ã¿
    # AIã¯JSONå½¢å¼ã§ã®å¿œç­”ã‚’å¼·åˆ¶ã•ã‚Œã¾ã™ã€‚
    # "properties" ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’åŸ‹ã‚ã‚‹ã“ã¨ã§ã€ä¼šè©±ã®æµã‚Œã‹ã‚‰ã‚¿ã‚¹ã‚¯ç™»éŒ²ã‚’è¡Œã†ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚
    prompt = f"""
{system_prompt}

Target Schema:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

Session History:
{history_text}

Current User Input:
{text if text else "(No text provided)"}

Restraints:
- You are a helpful AI assistant.
- Your output must be valid JSON ONLY.
- Structure:
{{
  "message": "Response to the user",
  "refined_text": "Refined version of the input, if applicable (or null)",
  "properties": {{ "Property Name": "Value" }} // Only if user intends to save data
}}
- If the user is just chatting, "properties" should be null.
- If the user wants to save/add data, fill "properties" according to the Schema.
"""
    return prompt


def validate_and_fix_json(json_str: str, schema: Dict[str, Any]) -> Dict[str, Any]:
    """
    AIã®JSONå¿œç­”ã‚’è§£æãƒ»æ¤œè¨¼ãƒ»ä¿®æ­£ã™ã‚‹é–¢æ•°
    
    LLMã¯æ™‚ã«Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å«ã‚“ã ã‚Šã€ä¸æ­£ãªJSONã‚’è¿”ã—ãŸã‚Šã™ã‚‹ãŸã‚ã€
    ãã‚Œã‚‰ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦Pythonè¾æ›¸ã¨ã—ã¦å®‰å…¨ã«å–ã‚Šå‡ºã—ã¾ã™ã€‚
    ã•ã‚‰ã«ã€ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã«å¾“ã£ã¦å‹å¤‰æ›ï¼ˆã‚­ãƒ£ã‚¹ãƒˆï¼‰ã‚’è¡Œã„ã€Notion APIã§ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãªã„å½¢å¼ã«æ•´ãˆã¾ã™ã€‚
    """
    # 1. Markdownè¨˜æ³•ã®é™¤å»
    # ```json ... ``` ã®ã‚ˆã†ãªè£…é£¾ã‚’å–ã‚Šé™¤ãã¾ã™ã€‚
    json_str = json_str.strip()
    if json_str.startswith("```json"):
        json_str = json_str[7:]
    if json_str.startswith("```"):
        json_str = json_str[3:]
    if json_str.endswith("```"):
        json_str = json_str[:-3]
    json_str = json_str.strip()
    
    try:
        data = json.loads(json_str)
    except json.JSONDecodeError:
        # JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ç°¡æ˜“ãƒªãƒˆãƒ©ã‚¤
        # ä½™è¨ˆãªæ¥é ­è¾/æ¥å°¾è¾ãŒã‚ã‚‹å ´åˆã«ã€æœ€åˆã®ä¸­æ‹¬å¼§ { ã¨æœ€å¾Œã®ä¸­æ‹¬å¼§ } ã®é–“ã‚’æŠ½å‡ºã—ã¦å†è©¦è¡Œã—ã¾ã™ã€‚
        start = json_str.find("{")
        end = json_str.rfind("}") + 1
        if start != -1 and end != -1:
            try:
                data = json.loads(json_str[start:end])
            except Exception:
                # å¾©æ—§ä¸èƒ½ãªå ´åˆã¯ç©ºã®è¾æ›¸ã‚’è¿”ã—ã¦å®‰å…¨ã«çµ‚äº†
                return {}
        else:
             return {}

    # 2. ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å‹æ¤œè¨¼ã¨ã‚­ãƒ£ã‚¹ãƒˆ (Robust Property Validation)
    # Notion APIã¯å‹ã«å³æ ¼ãªãŸã‚ã€ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’åŸºã«å„å€¤ã‚’é©åˆ‡ãªå½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚
    validated = {}
    for k, v in data.items():
        if k not in schema:
            continue
            
        target_type = schema[k]["type"]
        
        # å‹ã”ã¨ã®è©³ç´°ãªå‡¦ç†
        if target_type == "select":
            # Selectå‹: æ–‡å­—åˆ—ã«å¤‰æ›
            if isinstance(v, dict): v = v.get("name")
            if v:
                validated[k] = {"select": {"name": str(v)}}
                
        elif target_type == "multi_select":
            # Multi-Selectå‹: æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã«å¤‰æ›
            if not isinstance(v, list): v = [v]
            opts = []
            for item in v:
               if isinstance(item, dict): item = item.get("name")
               if item: opts.append({"name": str(item)})
            validated[k] = {"multi_select": opts}
            
        elif target_type == "status":
             # Statuså‹
             if isinstance(v, dict): v = v.get("name")
             if v:
                 validated[k] = {"status": {"name": str(v)}}
                 
        elif target_type == "date":
            # Dateå‹: YYYY-MM-DD æ–‡å­—åˆ—ã‚’æœŸå¾…
            if isinstance(v, dict): v = v.get("start")
            if v:
                validated[k] = {"date": {"start": str(v)}}
                
        elif target_type == "checkbox":
            # Checkboxå‹: çœŸå½å€¤
            validated[k] = {"checkbox": bool(v)}
            
        elif target_type == "number":
             # Numberå‹: æ•°å€¤å¤‰æ›
             try:
                 if v is not None:
                     validated[k] = {"number": float(v)}
             except (ValueError, TypeError):
                 # æ•°å€¤å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                 # ä¾‹: "abc" -> float() ã¯ ValueError
                 pass
                 
        elif target_type == "title":
             # Titleå‹: Rich Text ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
             if isinstance(v, list): v = "".join([t.get("plain_text","") for t in v if "plain_text" in t])
             validated[k] = {"title": [{"text": {"content": str(v)}}]}
             
        elif target_type == "rich_text":
             # Rich Textå‹
             if isinstance(v, list): v = "".join([t.get("plain_text","") for t in v if "plain_text" in t])
             validated[k] = {"rich_text": [{"text": {"content": str(v)}}]}
             
        elif target_type == "people":
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDãŒå¿…è¦ãªãŸã‚ã€ç¾åœ¨ã¯ç„¡è¦–ï¼ˆå®Ÿè£…é›£æ˜“åº¦é«˜ï¼‰
            pass
            
        elif target_type == "files":
             # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯è¤‡é›‘ãªãŸã‚ç„¡è¦–
             pass

    return validated


# --- NEW: High-level entry points ---

async def analyze_text_with_ai(
    text: str,
    schema: Dict[str, Any],
    recent_examples: List[Dict[str, Any]],
    system_prompt: str,
    model: Optional[str] = None
) -> Dict[str, Any]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æŠ½å‡ºã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    1. æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã®é¸æŠï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿/ç”»åƒã‚ã‚Šï¼‰
    2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    3. LLMã®å‘¼ã³å‡ºã—
    4. çµæœã®è§£æã¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    ã‚’ä¸€æ‹¬ã—ã¦è¡Œã„ã¾ã™ã€‚
    
    Args:
        text: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        schema: Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ
        recent_examples: æœ€è¿‘ã®ç™»éŒ²ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”¨ï¼‰
        system_prompt: ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®æŒ‡ç¤º
        model: ãƒ¢ãƒ‡ãƒ«ã®æ˜ç¤ºçš„ãªæŒ‡å®šï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•é¸æŠï¼‰
    
    Returns:
        {
            "properties": {...},  # Notionç™»éŒ²ç”¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
            "usage": {...},       # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡
            "cost": float,        # æ¨å®šã‚³ã‚¹ãƒˆ
            "model": str          # ä½¿ç”¨ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«å
        }
    """
    # ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•é¸æŠï¼ˆã“ã®é–¢æ•°ã¯ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®ã¿ã‚’æƒ³å®šï¼‰
    selected_model = select_model_for_input(has_image=False, user_selection=model)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    prompt = construct_prompt(text, schema, recent_examples, system_prompt)
    
    try:
        # LLMå‘¼ã³å‡ºã—
        result = await generate_json(prompt, model=selected_model)
        
        # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®æ¤œè¨¼ã¨ä¿®æ­£
        properties = validate_and_fix_json(result["content"], schema)
        
        return {
            "properties": properties,
            "usage": result["usage"],
            "cost": result["cost"],
            "model": result["model"]
        }
    
    except Exception as e:
        print(f"AI Analysis Failed: {e}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        # AIåˆ†æã«å¤±æ•—ã—ã¦ã‚‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ä¿å­˜ã§ãã‚‹ã‚ˆã†ã«
        # æœ€ä½é™ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æ§‹é€ ã‚’ä½œæˆã—ã¦è¿”ã—ã¾ã™ã€‚
        fallback = {}
        for k, v in schema.items():
            if v["type"] == "title":
                fallback[k] = {"title": [{"text": {"content": text}}]}
                break
        
        return {
            "properties": fallback,
            "usage": {},
            "cost": 0.0,
            "model": selected_model,
            "error": str(e)
        }


async def chat_analyze_text_with_ai(
    text: str,
    schema: Dict[str, Any],
    system_prompt: str,
    session_history: Optional[List[Dict[str, str]]] = None,
    image_data: Optional[str] = None,
    image_mime_type: Optional[str] = None,
    model: Optional[str] = None
) -> Dict[str, Any]:
    """
    ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆåˆ†æã®ãƒ¡ã‚¤ãƒ³é–¢æ•° (ç”»åƒå¯¾å¿œ)
    
    ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãã€ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆBase64ï¼‰ã‚’å«ã‚ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªå¯¾è©±ã‚’å‡¦ç†ã—ã¾ã™ã€‚
    ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®è‡ªç„¶ãªå¯¾è©±ã‚’è¡Œã„ãªãŒã‚‰ã€å¿…è¦ã«å¿œã˜ã¦ã‚¿ã‚¹ã‚¯æƒ…å ±ï¼ˆpropertiesï¼‰ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    
    Args:
        text: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        schema: Notionã®å¯¾è±¡ã‚¹ã‚­ãƒ¼ãƒ
        system_prompt: ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤º
        session_history: éå»ã®ä¼šè©±å±¥æ­´
        image_data: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆä»»æ„ï¼‰
        image_mime_type: ç”»åƒã®MIMEã‚¿ã‚¤ãƒ—ï¼ˆä»»æ„ï¼‰
        model: ãƒ¢ãƒ‡ãƒ«æŒ‡å®š
    
    Returns:
        dict: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ç²¾è£½ãƒ†ã‚­ã‚¹ãƒˆã€æŠ½å‡ºãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸
    """
    # ç”»åƒã®æœ‰ç„¡ã«åŸºã¥ããƒ¢ãƒ‡ãƒ«è‡ªå‹•é¸æŠ
    has_image = bool(image_data and image_mime_type)
    print(f"[Chat AI] Has image: {has_image}, User model selection: {model}")
    selected_model = select_model_for_input(has_image=has_image, user_selection=model)
    print(f"[Chat AI] Selected model: {selected_model}")
    
    # ä¼šè©±å±¥æ­´ã®æº–å‚™
    print(f"[Chat AI] Constructing messages, schema keys: {len(schema)}, history length: {len(session_history) if session_history else 0}")
    
    # ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã®æ•´å½¢
    schema_info = {}
    for k, v in schema.items():
        if isinstance(v, dict) and "type" in v:
             schema_info[k] = v['type']
             if v['type'] == 'select' and 'select' in v:
                schema_info[k] += f" options: {[o['name'] for o in v['select']['options']]}"
             elif v['type'] == 'multi_select' and 'multi_select' in v:
                schema_info[k] += f" options: {[o['name'] for o in v['multi_select']['options']]}"
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    system_message_content = f"""{system_prompt}

Target Schema:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

Restraints:
- You are a helpful AI assistant.
- Your output must be valid JSON ONLY.
- Structure:
{{
  "message": "Response to the user",
  "stamp": "ğŸ˜Š",  // Optional: Use a single emoji stamp to express emotion (happy, thinking, surprised, etc.)
  "refined_text": "Refined version of the input, if applicable (or null)",
  "properties": {{ "Property Name": "Value" }} // Only if user intends to save data
}}
- If the user is just chatting, "properties" should be null.
- If the user wants to save/add data, fill "properties" according to the Schema.
- Use "stamp" field to express your emotion with a single emoji when appropriate (e.g., ğŸ˜Š for happy, ğŸ¤” for thinking, ğŸ˜® for surprised, ğŸ‘ for approval, â¤ï¸ for appreciation). Only use when natural - not required for every response."""
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…åˆ—ã®æ§‹ç¯‰
    messages = [{"role": "system", "content": system_message_content}]
    
    # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆç”»åƒãƒ‡ãƒ¼ã‚¿ã¯å«ã¾ã‚Œãªã„ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
    if session_history:
        messages.extend(session_history)
    
    # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’è¿½åŠ 
    if has_image:
        #ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«: ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‘ãƒ¼ãƒ„ã‚’ä½œæˆ
        print(f"[Chat AI] Preparing multimodal message with image")
        current_user_content = prepare_multimodal_prompt(
            text or "(No text provided)",
            image_data,
            image_mime_type
        )
        messages.append({"role": "user", "content": current_user_content})
    else:
        # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿
        if text:
            messages.append({"role": "user", "content": text})
        else:
            messages.append({"role": "user", "content": "(No text provided)"})
    
    # LLMã®å‘¼ã³å‡ºã—ï¼ˆmessagesé…åˆ—ã‚’æ¸¡ã™ï¼‰
    print(f"[Chat AI] Calling LLM: {selected_model} with {len(messages)} messages")
    result = await generate_json(messages, model=selected_model)
    print(f"[Chat AI] LLM response received, length: {len(result['content'])}")
    json_resp = result["content"]
    
    # å¿œç­”ãƒ‡ãƒ¼ã‚¿ã®è§£æ
    try:
        data = json.loads(json_resp)
        
        # DEBUG: ç”Ÿã®è§£æçµæœã‚’ãƒ­ã‚°å‡ºåŠ›
        print(f"[Chat AI] Raw parsed response type: {type(data)}")
        print(f"[Chat AI] Raw parsed response: {data}")
        
        # æ–‡å­—åˆ—ãŒè¿”ã£ã¦ããŸå ´åˆã®å¯¾å¿œï¼ˆLLMãŒJSONå½¢å¼ã‚’è¿”ã•ãªã‹ã£ãŸå ´åˆï¼‰
        if isinstance(data, str):
            print(f"[Chat AI] Response is a string, wrapping in message dict")
            data = {"message": data}
        
        # ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã£ã¦ããŸå ´åˆã®å¯¾å¿œï¼ˆä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ï¼‰
        elif isinstance(data, list):
            print(f"[Chat AI] Response is a list, extracting first element")
            if data and isinstance(data[0], dict):
                data = data[0]
            else:
                data = {}

        if not data:
            data = {"message": "AIã‹ã‚‰æœ‰åŠ¹ãªå¿œç­”ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"}
            
        print(f"[Chat AI] After type handling: {data}")
        print(f"[Chat AI] Message field: {data.get('message') if isinstance(data, dict) else 'N/A'}")
        
    except json.JSONDecodeError:
        print(f"[Chat AI] JSON decode failed, attempting recovery from: {json_resp[:200]}")
        try:
            # éƒ¨åˆ†çš„ãªJSONã®æŠ½å‡ºã«ã‚ˆã‚‹ãƒªã‚«ãƒãƒª
            start = json_resp.find("{")
            end = json_resp.rfind("}") + 1
            data = json.loads(json_resp[start:end])
            print(f"[Chat AI] Recovered data: {data}")
        except Exception as e:
            print(f"[Chat AI] Recovery failed: {e}")
            data = {
                "message": "AIã®å¿œç­”ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                "raw_response": json_resp
            }
    
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å‘ã‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¿è¨¼
    if "message" not in data or not data["message"]:
        print(f"[Chat AI] Message missing or empty, generating fallback")
        
        # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒç›´æ¥è¿”ã•ã‚ŒãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
        has_properties = any(key in data for key in ["Title", "Content", "properties"])
        
        if "refined_text" in data and data["refined_text"]:
            data["message"] = f"ã‚¿ã‚¹ã‚¯åã‚’ã€Œ{data['refined_text']}ã€ã«ææ¡ˆã—ã¾ã™ã€‚"
        elif has_properties:
            if "Title" in data or "Content" in data:
                title_val = data.get("Title", "")
                data["message"] = f"å†…å®¹ã‚’æ•´ç†ã—ã¾ã—ãŸ: {title_val}" if title_val else "ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚"
            elif "properties" in data and data["properties"]:
                data["message"] = "ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚"
            else:
                data["message"] = "ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚"
        else:
            data["message"] = "ï¼ˆå¿œç­”å®Œäº†ï¼‰"
        print(f"[Chat AI] Fallback message: {data['message']}")

    
    # ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–: AIãŒãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚­ãƒ¼ã¨ã—ã¦è¿”ã—ãŸå ´åˆã®ä¿®æ­£
    if "properties" not in data:
        schema_keys = set(schema.keys())
        data_keys = set(data.keys())
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç­‰ä»¥å¤–ã®ã‚­ãƒ¼ã§ã€ã‚¹ã‚­ãƒ¼ãƒã¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨ã¿ãªã™
        property_keys = data_keys.intersection(schema_keys)
        
        if property_keys:
            print(f"[Chat AI] Normalizing direct properties: {property_keys}")
            properties = {key: data[key] for key in property_keys}
            # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‹ã‚‰å‰Šé™¤ã—ã¦ properties ã‚­ãƒ¼é…ä¸‹ã«ç§»å‹•
            for key in property_keys:
                del data[key]
            data["properties"] = properties
            print(f"[Chat AI] Normalized properties: {data['properties']}")
    
    # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®è©³ç´°æ¤œè¨¼
    if "properties" in data and data["properties"]:
        data["properties"] = validate_and_fix_json(
            json.dumps(data["properties"]),
            schema
        )
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä»˜ä¸
    data["usage"] = result["usage"]
    data["cost"] = result["cost"]
    data["model"] = result["model"]
    
    print(f"[Chat AI] Final response data: {data}")
    
    return data

